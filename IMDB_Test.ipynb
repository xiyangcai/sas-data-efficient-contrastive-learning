{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9605f63c-f46a-4993-ae94-41db47247ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8cac37f-dee3-4941-b995-7f3b2739ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, split='train', max_vocab_size=20000, embedding_dim=100):\n",
    "\n",
    "        RANDOM_SEED = 0\n",
    "\n",
    "        self.TEXT = data.Field(tokenize='spacy', include_lengths=True)\n",
    "        self.LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "        train_data, test_data = datasets.IMDB.splits(self.TEXT, self.LABEL)\n",
    "        # train_data, valid_data = train_data.split(random_state=random.seed(RANDOM_SEED), \n",
    "        #                                           split_ratio=0.8)\n",
    "\n",
    "        self.TEXT.build_vocab(train_data, max_size=max_vocab_size, vectors=f\"glove.6B.{embedding_dim}d\")\n",
    "        self.LABEL.build_vocab(train_data)\n",
    "\n",
    "        if split == 'train':\n",
    "            self.data = train_data\n",
    "        elif split == 'valid':\n",
    "            self.data = valid_data\n",
    "        elif split == 'test':\n",
    "            self.data = test_data\n",
    "        else:\n",
    "            raise ValueError(\"Invalid split. Use 'train', 'valid', or 'test'.\")\n",
    "\n",
    "        self.fields = {'text': self.TEXT, 'label': self.LABEL}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data[idx]\n",
    "        text = example.text\n",
    "        label = example.label\n",
    "        \n",
    "        return data.Example.fromlist([text, label], fields=[('text', self.TEXT), ('label', self.LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9946593e-9a54-43b2-b008-9d338a12bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataLoader:\n",
    "    def __init__(self, dataset, batch_size=64):\n",
    "        self.batch_size = batch_size\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Ensure `sort_key` is set based on the length of the text sequence\n",
    "        sort_key = lambda x: len(x.text)\n",
    "\n",
    "        # Create BucketIterator with the correct sort_key\n",
    "        self.iterator = data.BucketIterator(\n",
    "            dataset=dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sort_key=sort_key,  # Add sort_key here\n",
    "            sort_within_batch=True,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.iterator)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8249cb05-fe2c-41fe-b805-423232d7c87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "imdb_train_dataset = IMDbDataset(split='train')\n",
    "train_loader = IMDbDataLoader(imdb_train_dataset)\n",
    "for x in train_loader:\n",
    "    text, text_len = x.text\n",
    "    print(text.shape)\n",
    "    print(text_len.shape)\n",
    "    print(x.label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b3574e6-b806-458a-92e6-3ec90f63cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = imdb_train_dataset\n",
    "subset_fraction = 0.2\n",
    "subset_size = int(len(train_data) * subset_fraction)\n",
    "rand_idxs = np.random.choice(range(len(train_data)), subset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b216071-b5d5-4260-a025-d023c1b728e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_proc.dataset import TextDatasetSubset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b156b2-2a44-4d03-a623-00bf80a00e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_size = 20000\n",
    "subset_size = int(ori_size * 0.2)\n",
    "rand_idxs = np.random.choice(range(ori_size), subset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f312dae8-9f01-42e9-a821-73491cb59f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = TextDatasetSubset(rand_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4eb4678-f78b-4ab8-82aa-9149945b9fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data_proc.dataset.TextDatasetSubset at 0x7faed9070340>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381dd2a2-e91d-40c8-8293-dfb4b32f1cec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IMDbDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mIMDbDataset\u001b[49m(split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IMDbDataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = IMDbDataset(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbaefa-1e38-4202-8529-4ee2b54ad2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c271e43-50cc-4879-bc56-a7e9ddb81398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Example' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/site-packages/torchtext/data/field.py:302\u001b[0m, in \u001b[0;36mField.build_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m     \u001b[43mcounter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/collections/__init__.py:670\u001b[0m, in \u001b[0;36mCounter.update\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m         \u001b[43m_count_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Example' object is not iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m     new_data\u001b[38;5;241m.\u001b[39mappend(example)\n\u001b[1;32m     10\u001b[0m train_data\u001b[38;5;241m.\u001b[39mexamples \u001b[38;5;241m=\u001b[39m new_data\n\u001b[0;32m---> 13\u001b[0m \u001b[43mTEXT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mglove.6B.100d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m LABEL\u001b[38;5;241m.\u001b[39mbuild_vocab(train_data)\n",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/site-packages/torchtext/data/field.py:304\u001b[0m, in \u001b[0;36mField.build_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             counter\u001b[38;5;241m.\u001b[39mupdate(x)\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m             counter\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    305\u001b[0m specials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(OrderedDict\u001b[38;5;241m.\u001b[39mfromkeys(\n\u001b[1;32m    306\u001b[0m     tok \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munk_token, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_token,\n\u001b[1;32m    307\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meos_token] \u001b[38;5;241m+\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecials\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tok \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_cls(counter, specials\u001b[38;5;241m=\u001b[39mspecials, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Example' object is not iterable"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(tokenize='spacy', include_lengths=True)\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "idxs = rand_idxs\n",
    "new_data = []\n",
    "for i in idxs:\n",
    "    example = train_data[i]\n",
    "    new_example = data.Example.fromlist([example.text, example.label], [('text', TEXT), ('label', LABEL)])\n",
    "    new_data.append(example)\n",
    "train_data.examples = new_data\n",
    "\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=20000, vectors=f\"glove.6B.100d\")\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41c3d138-b669-48e6-9eb5-8a54a6b838b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Example' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/site-packages/torchtext/data/field.py:302\u001b[0m, in \u001b[0;36mField.build_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m     \u001b[43mcounter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/collections/__init__.py:670\u001b[0m, in \u001b[0;36mCounter.update\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m         \u001b[43m_count_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Example' object is not iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m subset \u001b[38;5;241m=\u001b[39m \u001b[43mTextDatasetSubset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrand_idxs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/sas-data-efficient-contrastive-learning/data_proc/dataset.py:196\u001b[0m, in \u001b[0;36mTextDatasetSubset.__init__\u001b[0;34m(self, dataset, idxs, max_vocab_size)\u001b[0m\n\u001b[1;32m    193\u001b[0m     new_data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[i])\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexamples \u001b[38;5;241m=\u001b[39m new_data\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTEXT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_vocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mglove.6B.100d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLABEL\u001b[38;5;241m.\u001b[39mbuild_vocab(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfields \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTEXT, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLABEL}\n",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/site-packages/torchtext/data/field.py:304\u001b[0m, in \u001b[0;36mField.build_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             counter\u001b[38;5;241m.\u001b[39mupdate(x)\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m             counter\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    305\u001b[0m specials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(OrderedDict\u001b[38;5;241m.\u001b[39mfromkeys(\n\u001b[1;32m    306\u001b[0m     tok \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munk_token, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_token,\n\u001b[1;32m    307\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meos_token] \u001b[38;5;241m+\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecials\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tok \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_cls(counter, specials\u001b[38;5;241m=\u001b[39mspecials, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Example' object is not iterable"
     ]
    }
   ],
   "source": [
    "subset = TextDatasetSubset(train_data, rand_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb1a718-b065-48b7-acba-fc129a3f24c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.IMDbDataset at 0x7ffaf621c430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = []\n",
    "for i in rand_idxs:\n",
    "    new_data.append(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc8bd1db-5a43-4781-b50c-6d0636a740ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_deletion(tokens, p=0.5):\n",
    "    if len(tokens) == 0:\n",
    "        return tokens\n",
    "\n",
    "    mask = np.random.rand(len(tokens)) > p\n",
    "    remaining_tokens = list(np.array(tokens)[mask])\n",
    "    # remaining_tokens = [token for token in tokens if random.uniform(0, 1) > p]\n",
    "    if len(remaining_tokens) == 0:\n",
    "        return [random.choice(tokens)]  # 如果全部删除，则随机保留一个\n",
    "    return remaining_tokens\n",
    "\n",
    "class AugmentedIMDbDataset(IMDbDataset):\n",
    "    def __init__(self, split='train', max_vocab_size=20000, embedding_dim=100, augment_function = None, num_positive=2):\n",
    "        super().__init__(split, max_vocab_size, embedding_dim)\n",
    "        self.num_positive = num_positive\n",
    "        self.augment_function = augment_function\n",
    "\n",
    "        augmented_examples = []\n",
    "        for example in self.data.examples:\n",
    "            for _ in range(self.num_positive):\n",
    "                example_augmented_text = self.augment_function(example.text)\n",
    "                new_example = data.Example.fromlist(\n",
    "                    [example_augmented_text, example.label], \n",
    "                    [('text', self.TEXT), ('label', self.LABEL)]\n",
    "                )\n",
    "                augmented_examples.append(new_example)\n",
    "        self.data.examples = augmented_examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return super().__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e06f0930-326b-4662-bd3f-05c8e390b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_imdb_train_dataset = AugmentedIMDbDataset(split='train',\n",
    "                                                    augment_function=random_deletion,\n",
    "                                                    num_positive=2)\n",
    "augmented_imdb_train_loader = IMDbDataLoader(augmented_imdb_train_dataset, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b8fb853-4a3b-4c70-8ed9-4063fe3273d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([516, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the loader to check the augmented samples\n",
    "for batch in augmented_imdb_train_loader:\n",
    "    text, text_length = batch.text\n",
    "    label = batch.label\n",
    "    print(text.shape)\n",
    "    print(text_length.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9eac90-f9e4-4acf-9924-9e2c71fb1a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0474499c-3fde-4943-8eb8-d1a9e4b73e41",
   "metadata": {},
   "source": [
    "## CLIP APPROX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "840aa8b8-1789-4c90-9ccc-5fab8287ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9fd8650-08e4-4bd3-9f35-192f4b592e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbGloveEmbeddedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, split='train', max_vocab_size=20000, embedding_dim=100):\n",
    "\n",
    "        RANDOM_SEED = 0\n",
    "\n",
    "        self.TEXT = data.Field(tokenize='spacy', include_lengths=True)\n",
    "        self.LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "        train_data, test_data = datasets.IMDB.splits(self.TEXT, self.LABEL)\n",
    "        train_data, valid_data = train_data.split(random_state=random.seed(RANDOM_SEED), \n",
    "                                                  split_ratio=0.8)\n",
    "\n",
    "        self.TEXT.build_vocab(train_data, max_size=max_vocab_size, vectors=f\"glove.6B.{embedding_dim}d\")\n",
    "        self.LABEL.build_vocab(train_data)\n",
    "\n",
    "        if split == 'train':\n",
    "            self.data = train_data\n",
    "        elif split == 'valid':\n",
    "            self.data = valid_data\n",
    "        elif split == 'test':\n",
    "            self.data = test_data\n",
    "        else:\n",
    "            raise ValueError(\"Invalid split. Use 'train', 'valid', or 'test'.\")\n",
    "\n",
    "        glove = GloVe(name='6B', dim=embedding_dim)\n",
    "        \n",
    "        texts = []\n",
    "        labels = []\n",
    "        \n",
    "        for sample in self.data:\n",
    "            text = sample.text\n",
    "            label = (1 if sample.label == 'pos' else 0)\n",
    "            \n",
    "            word_vectors = [glove[word.lower()] for word in text if word.lower() in glove.stoi]\n",
    "            texts.append(torch.stack(word_vectors).mean(0))\n",
    "            labels.append(label)\n",
    "        self.X = torch.stack(texts)\n",
    "        self.y = torch.Tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "924515e0-4088-4d0f-b2ee-fca14613befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e2805c3-18bd-49cf-aa58-85fc89f661fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GloveEmbeddedDataset = IMDbGloveEmbeddedDataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad970ca7-39ad-4dfd-8a8e-1378492dbe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(GloveEmbeddedDataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5079b4f-7f18-408e-bbeb-752ae5bbeafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for x in dl:\n",
    "    print(x[0].shape)\n",
    "    print(x[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a7083dd-9649-40f2-b1f6-20d9d0724ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerLinearModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TwoLayerLinearModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7641d130-8cbd-4768-8605-5e1e3171490e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a97e6198-f425-468d-8fa5-6aa912878f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0107, Training Accuracy: 32.0109\n",
      "Epoch [2/10], Loss: 0.0102, Training Accuracy: 32.0372\n",
      "Epoch [3/10], Loss: 0.0097, Training Accuracy: 32.0855\n",
      "Epoch [4/10], Loss: 0.0095, Training Accuracy: 32.1172\n",
      "Epoch [5/10], Loss: 0.0093, Training Accuracy: 32.1241\n",
      "Epoch [6/10], Loss: 0.0091, Training Accuracy: 32.1240\n",
      "Epoch [7/10], Loss: 0.0089, Training Accuracy: 32.1322\n",
      "Epoch [8/10], Loss: 0.0088, Training Accuracy: 32.1275\n",
      "Epoch [9/10], Loss: 0.0087, Training Accuracy: 32.1417\n",
      "Epoch [10/10], Loss: 0.0085, Training Accuracy: 32.1343\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerLinearModel(input_size=100, hidden_size=128, output_size=1)\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for inputs, targets in dl:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs.squeeze(), targets)  # Squeeze to remove unnecessary dimensions\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Compute the number of correct predictions\n",
    "        predictions = torch.round(torch.sigmoid(outputs))  # Convert logits to binary predictions\n",
    "        correct_predictions += (predictions == targets).sum().item()\n",
    "\n",
    "    # Print average loss and training accuracy for the epoch\n",
    "    average_loss = total_loss / len(GloveEmbeddedDataset)\n",
    "    accuracy = correct_predictions / len(GloveEmbeddedDataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}, Training Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aa4641bb-19c5-42f0-9426-ba713d0ae3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91d37784-996c-4b89-9801-e704d59ed109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_using_glove(dataset, device):\n",
    "    glove = GloVe(name='6B', dim=100)\n",
    "    texts = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        sample = dataset[i]\n",
    "        word_vectors = [glove[word.lower()] for word in sample.text if word.lower() in glove.stoi]\n",
    "        texts.append(torch.stack(word_vectors).mean(0))\n",
    "        \n",
    "    Z = torch.stack(texts).to(device)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6668b62-2363-4a97-b6a8-f849de50a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_classifier(\n",
    "    X: torch.tensor, \n",
    "    y: torch.tensor, \n",
    "    representation_dim: int,\n",
    "    num_classes: int,\n",
    "    device: torch.device,\n",
    "    reg_weight: float = 1e-3,\n",
    "    n_lbfgs_steps: int = 500,\n",
    "    verbose=False,\n",
    "):\n",
    "    if verbose:\n",
    "        print('\\nL2 Regularization weight: %g' % reg_weight)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    X_gpu = X.to(device)\n",
    "    y_gpu = y.to(device)\n",
    "\n",
    "    # Should be reset after each epoch for a completely independent evaluation\n",
    "    clf = nn.Linear(representation_dim, num_classes).to(device)\n",
    "    clf_optimizer = optim.LBFGS(clf.parameters())\n",
    "    clf.train()\n",
    "\n",
    "    for _ in tqdm(range(n_lbfgs_steps), desc=\"Training linear classifier using fraction of labels\", disable=not verbose):\n",
    "        def closure():\n",
    "            clf_optimizer.zero_grad()\n",
    "            raw_scores = clf(X_gpu)\n",
    "            loss = criterion(raw_scores, y_gpu)\n",
    "            loss += reg_weight * clf.weight.pow(2).sum()\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        clf_optimizer.step(closure)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92f976f0-e303-4db4-b407-99963f603083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_from_preds(preds):\n",
    "    partition = {}\n",
    "    for i, pred in enumerate(preds):\n",
    "        if pred not in partition:\n",
    "            partition[pred] = []\n",
    "        partition[pred].append(i)\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea04d93e-6021-47f0-bcf4-1b8be8dee181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_approx(\n",
    "    trainset: torch.utils.data.Dataset,\n",
    "    labeled_example_indices: List[int], \n",
    "    labeled_examples_labels: np.array,\n",
    "    num_classes: int,\n",
    "    device: torch.device, \n",
    "    batch_size: int = 512,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    Z = encode_using_glove(trainset, device)\n",
    "    clf = train_linear_classifier(\n",
    "        X=Z[labeled_example_indices], \n",
    "        y=torch.tensor(labeled_examples_labels), \n",
    "        representation_dim=len(Z[0]),\n",
    "        num_classes=num_classes,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )\n",
    "    preds = []\n",
    "    for start_idx in range(0, len(Z), batch_size):\n",
    "        preds.append(torch.argmax(clf(Z[start_idx:start_idx + batch_size]).detach(), dim=1).cpu())\n",
    "    preds = torch.cat(preds).numpy()\n",
    "\n",
    "    return partition_from_preds(preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08490ff8-7e2f-4834-be92-976385b4a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_labeled_examples_indices = random.sample(range(len(imdb_train_dataset)), 500)\n",
    "rand_labeled_examples_labels = [\n",
    "    1 if imdb_train_dataset[i].label == 'pos' else 0 for i in rand_labeled_examples_indices\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcf73219-58d7-4ef0-91a7-fab578b6666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train_dataset = IMDbDataset(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52812ed7-b79f-4b06-8dc0-d7715626debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = glove_approx(\n",
    "    trainset=imdb_train_dataset,\n",
    "    labeled_example_indices=rand_labeled_examples_indices, \n",
    "    labeled_examples_labels=rand_labeled_examples_labels,\n",
    "    num_classes=2,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5498f7a0-32d9-4ab1-819e-41a40703a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=128, hidden_dim=256, pre_embedding=None, output_dim=None):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "\n",
    "        if pre_embedding is not None:\n",
    "            self.embedding.weight.data.copy_(pre_embedding)\n",
    "\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=3)\n",
    "\n",
    "        self.representation_dim = hidden_dim\n",
    "\n",
    "        if output_dim is not None:\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        else:\n",
    "            self.fc = None\n",
    "\n",
    "    def forward(self, text, text_length):\n",
    "\n",
    "        # [sentence len, batch size] => [sentence len, batch size, embedding size]\n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, text_length.cpu()).cuda()\n",
    "\n",
    "        # [sentence len, batch size, embedding size] =>\n",
    "        #  output: [sentence len, batch size, hidden size]\n",
    "        #  hidden: [1, batch size, hidden size]\n",
    "        packed_output, (hidden, cell) = self.rnn(packed)\n",
    "\n",
    "        if self.fc is not None:\n",
    "            return self.fc(hidden.squeeze(0)).view(-1)\n",
    "        else:\n",
    "            return hidden[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a61a28f-ca5a-4410-b679-e48568bcb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = imdb_train_dataset\n",
    "net = LSTM(\n",
    "            input_dim=len(trainset.TEXT.vocab),\n",
    "            embedding_dim=100,\n",
    "            pre_embedding=trainset.TEXT.vocab.vectors\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5707111-85a8-4883-9110-c7ec4cd90c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db91ce40-30f1-4368-8482-7e59cf8a0629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35a7db5a-743b-4332-88aa-afe782282c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = net(text, text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9dca0dd-7854-4a64-a8e0-d8431e57e14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d025d7-286b-4c7f-baf3-577b8a4ec619",
   "metadata": {},
   "source": [
    "## SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33fcf817-f3a8-4972-b543-eb0a14e7eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "from typing import Dict, List, Optional\n",
    "import math \n",
    "import pickle\n",
    "import random \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sas.submodular_maximization import lazy_greedy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f209e2e2-5313-4a1b-a1e8-8341cfb35acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "\n",
    "class ProxyModel(nn.Module):\n",
    "    def __init__(self, net, critic):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.critic = critic\n",
    "    def forward(self, text, text_lengths):\n",
    "        return self.critic.project(self.net(text, text_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a89b8f71-b200-4aef-a488-0389093b49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSubsetDataset(ABC, Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: Dataset,\n",
    "        subset_fraction: float,\n",
    "        verbose: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param dataset: Original Dataset\n",
    "        :type dataset: Dataset\n",
    "        :param subset_fraction: Fractional size of subset\n",
    "        :type subset_fraction: float\n",
    "        :param verbose: verbose\n",
    "        :type verbose: boolean\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.subset_fraction = subset_fraction\n",
    "        self.len_dataset = len(self.dataset)\n",
    "        self.subset_size = int(self.len_dataset * self.subset_fraction)\n",
    "        self.subset_indices = None\n",
    "        self.verbose = verbose \n",
    "\n",
    "    def initialization_complete(self):\n",
    "        if self.verbose:\n",
    "            print(f\"Subset Size: {self.subset_size}\")\n",
    "            print(f\"Discarded {self.len_dataset - self.subset_size} examples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.subset_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get the index for the corresponding item in the original dataset\n",
    "        original_index = self.subset_indices[index]\n",
    "        \n",
    "        # Get the item from the original dataset at the corresponding index\n",
    "        original_item = self.dataset[original_index]\n",
    "        \n",
    "        return original_item\n",
    "    \n",
    "    def save_to_file(self, filename):\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(self.subset_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4acec1e0-7b4c-4e3c-81ea-9771e2070236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sas.submodular_maximization import lazy_greedy\n",
    "from sas.subset_dataset import BaseSubsetDataset, SubsetSelectionObjective\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_proc.NLPDataLoader import IMDbDataLoader\n",
    "\n",
    "\n",
    "class SASSubsetTextDataset(BaseSubsetDataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: Dataset,\n",
    "            subset_fraction: float,\n",
    "            num_downstream_classes: int,\n",
    "            device: torch.device,\n",
    "            approx_latent_class_partition: Dict[int, int],\n",
    "            proxy_model: Optional[nn.Module] = None,\n",
    "            augmentation_distance: Optional[Dict[int, np.array]] = None,\n",
    "            num_runs=1,\n",
    "            pairwise_distance_block_size: int = 1024,\n",
    "            threshold: float = 0.0,\n",
    "            verbose: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        dataset: Dataset\n",
    "            Original dataset for contrastive learning. Assumes that dataset[i] returns a list of augmented views of the original example i.\n",
    "\n",
    "        subset_fraction: float\n",
    "            Fractional size of subset.\n",
    "\n",
    "        num_downstream_classes: int\n",
    "            Number of downstream classes (can be an estimate).\n",
    "\n",
    "        proxy_model: nn.Module\n",
    "            Proxy model to calculate the augmentation distance (and kmeans clustering if the avoid clip option is chosen).\n",
    "\n",
    "        augmentation_distance: Dict[int, np.array]\n",
    "            Pass a precomputed dictionary containing augmentation distance for each latent class.\n",
    "\n",
    "        num_augmentations: int\n",
    "            Number of augmentations to consider while approximating the augmentation distance.\n",
    "\n",
    "        pairwise_distance_block_size: int\n",
    "            Block size for calculating pairwise distance. This is just to optimize GPU usage while calculating pairwise distance and will not affect the subset created in any way.\n",
    "\n",
    "        verbose: boolean\n",
    "            Verbosity of the output.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            dataset=dataset,\n",
    "            subset_fraction=subset_fraction,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        self.device = device\n",
    "        self.num_downstream_classes = num_downstream_classes\n",
    "        self.proxy_model = proxy_model\n",
    "        self.partition = approx_latent_class_partition\n",
    "        self.augmentation_distance = augmentation_distance\n",
    "        self.num_runs = num_runs\n",
    "        self.pairwise_distance_block_size = pairwise_distance_block_size\n",
    "\n",
    "        if self.augmentation_distance is None:\n",
    "            self.augmentation_distance = self.approximate_augmentation_distance()\n",
    "\n",
    "        class_wise_idx = {}\n",
    "        for latent_class in tqdm(self.partition.keys(), desc=\"Subset Selection:\", disable=not verbose):\n",
    "            F = SubsetSelectionObjective(self.augmentation_distance[latent_class].copy(), threshold=threshold)\n",
    "            class_wise_idx[latent_class] = lazy_greedy(F, range(len(self.augmentation_distance[latent_class])),\n",
    "                                                       len(self.augmentation_distance[latent_class]))\n",
    "            class_wise_idx[latent_class] = [self.partition[latent_class][i] for i in class_wise_idx[latent_class]]\n",
    "\n",
    "        self.subset_indices = []\n",
    "        for latent_class in class_wise_idx.keys():\n",
    "            l = len(class_wise_idx[latent_class])\n",
    "            self.subset_indices.extend(class_wise_idx[latent_class][:int(self.subset_fraction * l)])\n",
    "\n",
    "        self.initialization_complete()\n",
    "\n",
    "    def approximate_augmentation_distance(self):\n",
    "        self.proxy_model = self.proxy_model.to(self.device)\n",
    "\n",
    "        # Initialize augmentation distance with all 0s\n",
    "        augmentation_distance = {}\n",
    "        Z = self.encode_trainset()\n",
    "        for latent_class in self.partition.keys():\n",
    "            Z_partition = Z[self.partition[latent_class]]\n",
    "            pairwise_distance = SASSubsetTextDataset.pairwise_distance(Z_partition, Z_partition)\n",
    "            augmentation_distance[latent_class] = pairwise_distance.copy()\n",
    "        return augmentation_distance\n",
    "\n",
    "    def encode_trainset(self):\n",
    "        trainloader = IMDbDataLoader(self.dataset, batch_size=self.pairwise_distance_block_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Z = []\n",
    "            for input in trainloader:\n",
    "                text, text_lengths = input.text\n",
    "                Z.append(self.proxy_model(text.to(self.device), text_lengths.to(self.device)))\n",
    "        return torch.cat(Z, dim=0)\n",
    "\n",
    "    def encode_augmented_trainset(self, num_positives=1):\n",
    "        trainloader = IMDbDataLoader(self.dataset, batch_size=self.pairwise_distance_block_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Z = []\n",
    "\n",
    "            for input in trainloader:\n",
    "                text, text_lengths = input.text\n",
    "                Z.append(self.proxy_model(text.to(self.device), text_lengths.to(self.device)))\n",
    "            Z = torch.stack(Z)\n",
    "\n",
    "            aug_z = []\n",
    "            idxs = torch.arange(0, len(Z), num_positives)\n",
    "            for i in range(num_positives):\n",
    "                aug_z.append(Z[idxs + i])\n",
    "\n",
    "            Z = torch.cat(aug_z, dim=0)\n",
    "        return Z\n",
    "\n",
    "    @staticmethod\n",
    "    def pairwise_distance(Z1: torch.tensor, Z2: torch.tensor, block_size: int = 1024):\n",
    "        similarity_matrices = []\n",
    "        for i in range(Z1.shape[0] // block_size + 1):\n",
    "            similarity_matrices_i = []\n",
    "            e = Z1[i * block_size:(i + 1) * block_size]\n",
    "            for j in range(Z2.shape[0] // block_size + 1):\n",
    "                e_t = Z2[j * block_size:(j + 1) * block_size].t()\n",
    "                similarity_matrices_i.append(\n",
    "                    np.array(\n",
    "                        torch.cosine_similarity(e[:, :, None], e_t[None, :, :]).detach().cpu()\n",
    "                    )\n",
    "                )\n",
    "            similarity_matrices.append(similarity_matrices_i)\n",
    "        similarity_matrix = np.block(similarity_matrices)\n",
    "\n",
    "        return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "395ed8c0-cd93-42a2-b9cb-b4ce4c0cdb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subset Selection:: 100%|██████████████████████████| 2/2 [00:06<00:00,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset Size: 4000\n",
      "Discarded 16000 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from sas.subset_dataset import SASSubsetDataset\n",
    "net = torch.load(\"2023-12-0317:57:33.875617-imdb-LSTM-99-net.pt\")\n",
    "critic = torch.load(\"2023-12-0317:57:33.875617-imdb-LSTM-99-critic.pt\")\n",
    "proxy_model = ProxyModel(net, critic)\n",
    "from data_proc import NLPDataLoader\n",
    "     \n",
    "subset_dataset = SASSubsetTextDataset(\n",
    "    dataset=imdb_train_dataset,\n",
    "    subset_fraction=0.2,\n",
    "    num_downstream_classes=2,\n",
    "    device=device,\n",
    "    proxy_model=proxy_model,\n",
    "    approx_latent_class_partition=partition,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "27c01698-ab67-4c77-a6b9-e13de3adbef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8472,\n",
       " 14893,\n",
       " 2441,\n",
       " 9287,\n",
       " 4128,\n",
       " 9733,\n",
       " 6734,\n",
       " 3756,\n",
       " 10750,\n",
       " 5381,\n",
       " 11370,\n",
       " 14528,\n",
       " 5011,\n",
       " 8044,\n",
       " 1009,\n",
       " 6437,\n",
       " 9895,\n",
       " 15517,\n",
       " 3662,\n",
       " 16773,\n",
       " 16960,\n",
       " 19142,\n",
       " 2366,\n",
       " 6584,\n",
       " 612,\n",
       " 16492,\n",
       " 2273,\n",
       " 2153,\n",
       " 352,\n",
       " 5307,\n",
       " 14809,\n",
       " 5467,\n",
       " 9310,\n",
       " 3739,\n",
       " 19251,\n",
       " 8382,\n",
       " 3999,\n",
       " 14050,\n",
       " 8120,\n",
       " 19840,\n",
       " 2623,\n",
       " 13325,\n",
       " 14108,\n",
       " 13882,\n",
       " 19774,\n",
       " 12487,\n",
       " 3031,\n",
       " 8783,\n",
       " 5702,\n",
       " 18406,\n",
       " 13661,\n",
       " 14383,\n",
       " 3590,\n",
       " 297,\n",
       " 8994,\n",
       " 6536,\n",
       " 10220,\n",
       " 6939,\n",
       " 9346,\n",
       " 3534,\n",
       " 18232,\n",
       " 7234,\n",
       " 5494,\n",
       " 8773,\n",
       " 13392,\n",
       " 13361,\n",
       " 9649,\n",
       " 7227,\n",
       " 7818,\n",
       " 7297,\n",
       " 8396,\n",
       " 8812,\n",
       " 13363,\n",
       " 11936,\n",
       " 2148,\n",
       " 14019,\n",
       " 7158,\n",
       " 9240,\n",
       " 16081,\n",
       " 116,\n",
       " 6411,\n",
       " 10525,\n",
       " 8466,\n",
       " 2847,\n",
       " 1672,\n",
       " 1546,\n",
       " 9799,\n",
       " 711,\n",
       " 11099,\n",
       " 8751,\n",
       " 13518,\n",
       " 8404,\n",
       " 686,\n",
       " 19820,\n",
       " 1357,\n",
       " 18297,\n",
       " 4207,\n",
       " 7207,\n",
       " 4424,\n",
       " 15851,\n",
       " 3086,\n",
       " 6361,\n",
       " 12913,\n",
       " 16329,\n",
       " 1291,\n",
       " 443,\n",
       " 6782,\n",
       " 18708,\n",
       " 2682,\n",
       " 18313,\n",
       " 3255,\n",
       " 11058,\n",
       " 17051,\n",
       " 17041,\n",
       " 12497,\n",
       " 7049,\n",
       " 1614,\n",
       " 13943,\n",
       " 15459,\n",
       " 19240,\n",
       " 10506,\n",
       " 9604,\n",
       " 5478,\n",
       " 11688,\n",
       " 15923,\n",
       " 15820,\n",
       " 12976,\n",
       " 12152,\n",
       " 16733,\n",
       " 8320,\n",
       " 12130,\n",
       " 17530,\n",
       " 6470,\n",
       " 7232,\n",
       " 18166,\n",
       " 19813,\n",
       " 5782,\n",
       " 1235,\n",
       " 1877,\n",
       " 9899,\n",
       " 16163,\n",
       " 2579,\n",
       " 18248,\n",
       " 444,\n",
       " 5707,\n",
       " 8840,\n",
       " 15258,\n",
       " 1222,\n",
       " 12992,\n",
       " 9038,\n",
       " 9187,\n",
       " 8542,\n",
       " 17871,\n",
       " 5665,\n",
       " 10777,\n",
       " 2332,\n",
       " 12132,\n",
       " 2471,\n",
       " 8419,\n",
       " 12737,\n",
       " 15777,\n",
       " 19521,\n",
       " 17510,\n",
       " 7533,\n",
       " 12098,\n",
       " 16598,\n",
       " 4469,\n",
       " 320,\n",
       " 10948,\n",
       " 15500,\n",
       " 8047,\n",
       " 16110,\n",
       " 12177,\n",
       " 17349,\n",
       " 7125,\n",
       " 16422,\n",
       " 14615,\n",
       " 13093,\n",
       " 4773,\n",
       " 8704,\n",
       " 14674,\n",
       " 8152,\n",
       " 7228,\n",
       " 5957,\n",
       " 4930,\n",
       " 150,\n",
       " 19428,\n",
       " 9364,\n",
       " 12684,\n",
       " 12514,\n",
       " 18695,\n",
       " 5812,\n",
       " 1349,\n",
       " 15469,\n",
       " 7195,\n",
       " 4827,\n",
       " 13809,\n",
       " 4182,\n",
       " 11402,\n",
       " 14913,\n",
       " 17025,\n",
       " 13065,\n",
       " 9632,\n",
       " 5659,\n",
       " 2126,\n",
       " 13749,\n",
       " 15932,\n",
       " 6638,\n",
       " 16142,\n",
       " 5460,\n",
       " 18732,\n",
       " 14126,\n",
       " 6637,\n",
       " 2941,\n",
       " 16953,\n",
       " 2688,\n",
       " 16411,\n",
       " 7823,\n",
       " 2437,\n",
       " 8010,\n",
       " 825,\n",
       " 19220,\n",
       " 4651,\n",
       " 3258,\n",
       " 5240,\n",
       " 7788,\n",
       " 10285,\n",
       " 19513,\n",
       " 18797,\n",
       " 17654,\n",
       " 2103,\n",
       " 18179,\n",
       " 1367,\n",
       " 13178,\n",
       " 12404,\n",
       " 7683,\n",
       " 2954,\n",
       " 5683,\n",
       " 13128,\n",
       " 17110,\n",
       " 3309,\n",
       " 9250,\n",
       " 14345,\n",
       " 17970,\n",
       " 1078,\n",
       " 18267,\n",
       " 5942,\n",
       " 2019,\n",
       " 11320,\n",
       " 1402,\n",
       " 18482,\n",
       " 13176,\n",
       " 16740,\n",
       " 632,\n",
       " 2868,\n",
       " 1148,\n",
       " 12432,\n",
       " 2018,\n",
       " 12849,\n",
       " 8589,\n",
       " 3746,\n",
       " 8979,\n",
       " 7514,\n",
       " 5852,\n",
       " 13666,\n",
       " 18131,\n",
       " 6929,\n",
       " 17310,\n",
       " 1637,\n",
       " 15484,\n",
       " 5204,\n",
       " 5294,\n",
       " 19627,\n",
       " 11899,\n",
       " 7558,\n",
       " 7986,\n",
       " 19983,\n",
       " 649,\n",
       " 16668,\n",
       " 1341,\n",
       " 3449,\n",
       " 14289,\n",
       " 14967,\n",
       " 806,\n",
       " 3035,\n",
       " 7951,\n",
       " 9618,\n",
       " 7270,\n",
       " 3602,\n",
       " 17581,\n",
       " 907,\n",
       " 12508,\n",
       " 19910,\n",
       " 14715,\n",
       " 13241,\n",
       " 11233,\n",
       " 13467,\n",
       " 3412,\n",
       " 15031,\n",
       " 13375,\n",
       " 5167,\n",
       " 13914,\n",
       " 16534,\n",
       " 9768,\n",
       " 15000,\n",
       " 14233,\n",
       " 19227,\n",
       " 16965,\n",
       " 14598,\n",
       " 16654,\n",
       " 14677,\n",
       " 5085,\n",
       " 14173,\n",
       " 3387,\n",
       " 9852,\n",
       " 4810,\n",
       " 3770,\n",
       " 8092,\n",
       " 14122,\n",
       " 13840,\n",
       " 1185,\n",
       " 18467,\n",
       " 17180,\n",
       " 15786,\n",
       " 233,\n",
       " 16429,\n",
       " 17969,\n",
       " 3872,\n",
       " 19717,\n",
       " 9797,\n",
       " 9651,\n",
       " 15200,\n",
       " 19457,\n",
       " 16252,\n",
       " 1657,\n",
       " 13220,\n",
       " 3362,\n",
       " 12061,\n",
       " 5067,\n",
       " 5741,\n",
       " 14702,\n",
       " 9125,\n",
       " 875,\n",
       " 3501,\n",
       " 12820,\n",
       " 12603,\n",
       " 9503,\n",
       " 958,\n",
       " 12865,\n",
       " 15715,\n",
       " 16823,\n",
       " 4699,\n",
       " 5573,\n",
       " 3139,\n",
       " 3920,\n",
       " 12378,\n",
       " 3543,\n",
       " 2417,\n",
       " 2681,\n",
       " 15688,\n",
       " 1579,\n",
       " 4285,\n",
       " 13188,\n",
       " 10117,\n",
       " 13006,\n",
       " 8957,\n",
       " 13542,\n",
       " 9432,\n",
       " 14015,\n",
       " 13223,\n",
       " 2709,\n",
       " 10073,\n",
       " 7862,\n",
       " 14873,\n",
       " 11767,\n",
       " 11166,\n",
       " 10625,\n",
       " 8420,\n",
       " 1591,\n",
       " 9599,\n",
       " 13152,\n",
       " 13618,\n",
       " 3395,\n",
       " 3115,\n",
       " 5269,\n",
       " 11247,\n",
       " 18454,\n",
       " 19325,\n",
       " 18495,\n",
       " 5427,\n",
       " 168,\n",
       " 6974,\n",
       " 7085,\n",
       " 18589,\n",
       " 10241,\n",
       " 15180,\n",
       " 7498,\n",
       " 12979,\n",
       " 10871,\n",
       " 10866,\n",
       " 482,\n",
       " 1093,\n",
       " 16992,\n",
       " 375,\n",
       " 9848,\n",
       " 4200,\n",
       " 18992,\n",
       " 3957,\n",
       " 9228,\n",
       " 6084,\n",
       " 11450,\n",
       " 2695,\n",
       " 3636,\n",
       " 16634,\n",
       " 12090,\n",
       " 12987,\n",
       " 6495,\n",
       " 9829,\n",
       " 904,\n",
       " 9625,\n",
       " 1845,\n",
       " 10244,\n",
       " 12718,\n",
       " 11514,\n",
       " 15149,\n",
       " 3293,\n",
       " 11833,\n",
       " 8441,\n",
       " 6455,\n",
       " 6395,\n",
       " 14990,\n",
       " 6425,\n",
       " 2039,\n",
       " 12317,\n",
       " 1073,\n",
       " 7981,\n",
       " 6534,\n",
       " 13500,\n",
       " 1537,\n",
       " 68,\n",
       " 13659,\n",
       " 18546,\n",
       " 8254,\n",
       " 2658,\n",
       " 10616,\n",
       " 5353,\n",
       " 7690,\n",
       " 6490,\n",
       " 9357,\n",
       " 8020,\n",
       " 9569,\n",
       " 14005,\n",
       " 9814,\n",
       " 9018,\n",
       " 6246,\n",
       " 16230,\n",
       " 10529,\n",
       " 15238,\n",
       " 7672,\n",
       " 378,\n",
       " 10251,\n",
       " 10504,\n",
       " 2138,\n",
       " 6543,\n",
       " 15582,\n",
       " 19859,\n",
       " 7345,\n",
       " 10402,\n",
       " 15476,\n",
       " 13558,\n",
       " 6333,\n",
       " 15341,\n",
       " 1351,\n",
       " 4855,\n",
       " 16951,\n",
       " 1133,\n",
       " 15534,\n",
       " 19905,\n",
       " 12676,\n",
       " 2567,\n",
       " 17982,\n",
       " 18619,\n",
       " 17828,\n",
       " 19836,\n",
       " 9902,\n",
       " 2580,\n",
       " 12372,\n",
       " 17591,\n",
       " 14043,\n",
       " 10826,\n",
       " 6593,\n",
       " 16065,\n",
       " 18923,\n",
       " 16473,\n",
       " 11309,\n",
       " 2706,\n",
       " 13587,\n",
       " 9059,\n",
       " 8681,\n",
       " 8211,\n",
       " 10899,\n",
       " 19382,\n",
       " 12888,\n",
       " 17702,\n",
       " 6888,\n",
       " 3540,\n",
       " 18562,\n",
       " 10716,\n",
       " 18334,\n",
       " 5987,\n",
       " 1856,\n",
       " 5621,\n",
       " 2199,\n",
       " 6990,\n",
       " 6783,\n",
       " 6022,\n",
       " 10281,\n",
       " 14634,\n",
       " 5493,\n",
       " 2921,\n",
       " 19412,\n",
       " 14676,\n",
       " 12835,\n",
       " 4163,\n",
       " 16907,\n",
       " 17610,\n",
       " 11084,\n",
       " 17017,\n",
       " 7866,\n",
       " 8567,\n",
       " 8958,\n",
       " 12618,\n",
       " 14520,\n",
       " 12556,\n",
       " 17055,\n",
       " 2917,\n",
       " 14167,\n",
       " 7968,\n",
       " 9060,\n",
       " 19056,\n",
       " 12426,\n",
       " 17204,\n",
       " 9298,\n",
       " 19629,\n",
       " 4544,\n",
       " 9265,\n",
       " 8950,\n",
       " 16594,\n",
       " 6109,\n",
       " 13852,\n",
       " 18352,\n",
       " 5466,\n",
       " 10078,\n",
       " 2550,\n",
       " 1366,\n",
       " 11571,\n",
       " 10950,\n",
       " 19347,\n",
       " 14254,\n",
       " 7540,\n",
       " 18036,\n",
       " 6570,\n",
       " 14681,\n",
       " 15635,\n",
       " 10958,\n",
       " 2946,\n",
       " 12510,\n",
       " 1178,\n",
       " 13037,\n",
       " 9308,\n",
       " 3124,\n",
       " 2407,\n",
       " 4024,\n",
       " 12099,\n",
       " 12581,\n",
       " 1059,\n",
       " 2229,\n",
       " 18621,\n",
       " 3055,\n",
       " 14142,\n",
       " 2723,\n",
       " 12174,\n",
       " 4296,\n",
       " 7706,\n",
       " 7108,\n",
       " 17901,\n",
       " 4188,\n",
       " 19465,\n",
       " 13219,\n",
       " 5147,\n",
       " 14179,\n",
       " 9521,\n",
       " 18059,\n",
       " 9713,\n",
       " 738,\n",
       " 4077,\n",
       " 16307,\n",
       " 14435,\n",
       " 128,\n",
       " 9239,\n",
       " 13509,\n",
       " 18081,\n",
       " 17389,\n",
       " 682,\n",
       " 18894,\n",
       " 7994,\n",
       " 6049,\n",
       " 11459,\n",
       " 17684,\n",
       " 13823,\n",
       " 11982,\n",
       " 520,\n",
       " 9422,\n",
       " 9619,\n",
       " 5656,\n",
       " 681,\n",
       " 977,\n",
       " 16788,\n",
       " 8865,\n",
       " 14693,\n",
       " 16858,\n",
       " 11748,\n",
       " 5539,\n",
       " 1127,\n",
       " 4216,\n",
       " 4447,\n",
       " 18246,\n",
       " 3153,\n",
       " 15551,\n",
       " 4086,\n",
       " 18063,\n",
       " 7499,\n",
       " 273,\n",
       " 10665,\n",
       " 13259,\n",
       " 16463,\n",
       " 10070,\n",
       " 6312,\n",
       " 336,\n",
       " 3970,\n",
       " 4394,\n",
       " 8157,\n",
       " 4383,\n",
       " 7997,\n",
       " 1973,\n",
       " 9770,\n",
       " 8989,\n",
       " 5424,\n",
       " 14098,\n",
       " 8978,\n",
       " 2375,\n",
       " 3225,\n",
       " 11877,\n",
       " 3869,\n",
       " 14728,\n",
       " 6428,\n",
       " 2184,\n",
       " 8995,\n",
       " 10051,\n",
       " 11174,\n",
       " 10770,\n",
       " 13820,\n",
       " 7724,\n",
       " 8197,\n",
       " 15403,\n",
       " 15731,\n",
       " 7584,\n",
       " 9553,\n",
       " 14599,\n",
       " 15253,\n",
       " 15787,\n",
       " 2769,\n",
       " 8209,\n",
       " 10464,\n",
       " 7669,\n",
       " 13004,\n",
       " 6423,\n",
       " 15747,\n",
       " 13760,\n",
       " 11692,\n",
       " 16324,\n",
       " 4588,\n",
       " 19842,\n",
       " 17758,\n",
       " 12985,\n",
       " 12548,\n",
       " 12787,\n",
       " 200,\n",
       " 5604,\n",
       " 1976,\n",
       " 2267,\n",
       " 492,\n",
       " 17792,\n",
       " 8637,\n",
       " 8892,\n",
       " 9436,\n",
       " 5023,\n",
       " 11846,\n",
       " 2673,\n",
       " 11709,\n",
       " 17033,\n",
       " 2764,\n",
       " 16139,\n",
       " 16042,\n",
       " 17907,\n",
       " 2978,\n",
       " 18676,\n",
       " 15919,\n",
       " 14723,\n",
       " 16991,\n",
       " 13731,\n",
       " 17920,\n",
       " 16015,\n",
       " 6408,\n",
       " 12851,\n",
       " 13080,\n",
       " 11036,\n",
       " 18397,\n",
       " 4952,\n",
       " 550,\n",
       " 14883,\n",
       " 10148,\n",
       " 14521,\n",
       " 8331,\n",
       " 3004,\n",
       " 12857,\n",
       " 14356,\n",
       " 13610,\n",
       " 18133,\n",
       " 12859,\n",
       " 8500,\n",
       " 14497,\n",
       " 4568,\n",
       " 18914,\n",
       " 18441,\n",
       " 1383,\n",
       " 13197,\n",
       " 12210,\n",
       " 11012,\n",
       " 19025,\n",
       " 11331,\n",
       " 8352,\n",
       " 3946,\n",
       " 1782,\n",
       " 17820,\n",
       " 18929,\n",
       " 17558,\n",
       " 18092,\n",
       " 3381,\n",
       " 2319,\n",
       " 19950,\n",
       " 5250,\n",
       " 5814,\n",
       " 466,\n",
       " 6424,\n",
       " 18119,\n",
       " 11302,\n",
       " 9538,\n",
       " 953,\n",
       " 3582,\n",
       " 14759,\n",
       " 12332,\n",
       " 13927,\n",
       " 17931,\n",
       " 19849,\n",
       " 2642,\n",
       " 7939,\n",
       " 3447,\n",
       " 3647,\n",
       " 10224,\n",
       " 11220,\n",
       " 963,\n",
       " 11173,\n",
       " 4359,\n",
       " 12342,\n",
       " 14223,\n",
       " 8191,\n",
       " 2942,\n",
       " 3786,\n",
       " 3152,\n",
       " 6185,\n",
       " 16407,\n",
       " 17187,\n",
       " 19018,\n",
       " 13092,\n",
       " 10534,\n",
       " 12374,\n",
       " 1278,\n",
       " 11805,\n",
       " 18220,\n",
       " 6088,\n",
       " 8775,\n",
       " 10676,\n",
       " 15728,\n",
       " 3981,\n",
       " 19362,\n",
       " 12577,\n",
       " 4592,\n",
       " 1684,\n",
       " 17866,\n",
       " 15259,\n",
       " 18251,\n",
       " 287,\n",
       " 9594,\n",
       " 16079,\n",
       " 2594,\n",
       " 1269,\n",
       " 17264,\n",
       " 4575,\n",
       " 12465,\n",
       " 2686,\n",
       " 10309,\n",
       " 12329,\n",
       " 15560,\n",
       " 3280,\n",
       " 9931,\n",
       " 19488,\n",
       " 17079,\n",
       " 2951,\n",
       " 184,\n",
       " 18887,\n",
       " 6784,\n",
       " 4075,\n",
       " 4386,\n",
       " 2676,\n",
       " 7678,\n",
       " 3298,\n",
       " 10549,\n",
       " 18768,\n",
       " 16937,\n",
       " 17383,\n",
       " 10211,\n",
       " 5300,\n",
       " 15721,\n",
       " 19926,\n",
       " 2815,\n",
       " 6477,\n",
       " 12015,\n",
       " 804,\n",
       " 4144,\n",
       " 6563,\n",
       " 15386,\n",
       " 13007,\n",
       " 4400,\n",
       " 17224,\n",
       " 19434,\n",
       " 6018,\n",
       " 14701,\n",
       " 7208,\n",
       " 9413,\n",
       " 13490,\n",
       " 7334,\n",
       " 1116,\n",
       " 6296,\n",
       " 719,\n",
       " 4121,\n",
       " 933,\n",
       " 11734,\n",
       " 10383,\n",
       " 5635,\n",
       " 14569,\n",
       " 19520,\n",
       " 9739,\n",
       " 18387,\n",
       " 17145,\n",
       " 12807,\n",
       " 4079,\n",
       " 12484,\n",
       " 2787,\n",
       " 7391,\n",
       " 4698,\n",
       " 2526,\n",
       " 9157,\n",
       " 3556,\n",
       " 10663,\n",
       " 7260,\n",
       " 594,\n",
       " 15955,\n",
       " 8112,\n",
       " 15377,\n",
       " 15579,\n",
       " 3762,\n",
       " 8300,\n",
       " 15622,\n",
       " 17692,\n",
       " 5261,\n",
       " 14826,\n",
       " 18948,\n",
       " 19676,\n",
       " 13547,\n",
       " 10334,\n",
       " 7462,\n",
       " 5921,\n",
       " 7993,\n",
       " 15112,\n",
       " 5945,\n",
       " 10036,\n",
       " 8038,\n",
       " 5223,\n",
       " 452,\n",
       " 4822,\n",
       " 12519,\n",
       " 16570,\n",
       " 19171,\n",
       " 6365,\n",
       " 15569,\n",
       " 4221,\n",
       " 5254,\n",
       " 9671,\n",
       " 5863,\n",
       " 4518,\n",
       " 17671,\n",
       " 3034,\n",
       " 7511,\n",
       " 17761,\n",
       " 15749,\n",
       " 9010,\n",
       " 10843,\n",
       " 18783,\n",
       " 249,\n",
       " 5097,\n",
       " 532,\n",
       " 8696,\n",
       " 1533,\n",
       " 856,\n",
       " 6520,\n",
       " 7838,\n",
       " 1848,\n",
       " 18312,\n",
       " 1639,\n",
       " 8265,\n",
       " 1347,\n",
       " 9611,\n",
       " 17196,\n",
       " 11631,\n",
       " 7975,\n",
       " 8571,\n",
       " 17817,\n",
       " 14717,\n",
       " 10451,\n",
       " 14770,\n",
       " 18778,\n",
       " 2466,\n",
       " 18832,\n",
       " 15356,\n",
       " 3167,\n",
       " 3829,\n",
       " 1995,\n",
       " 3154,\n",
       " 11079,\n",
       " 15142,\n",
       " 3632,\n",
       " 13076,\n",
       " 14048,\n",
       " 10282,\n",
       " 2409,\n",
       " 11140,\n",
       " 1238,\n",
       " 10133,\n",
       " 4335,\n",
       " 16785,\n",
       " 10499,\n",
       " 16879,\n",
       " 2052,\n",
       " 13013,\n",
       " 14371,\n",
       " 14269,\n",
       " 14835,\n",
       " 6877,\n",
       " 596,\n",
       " 6065,\n",
       " 13829,\n",
       " 15102,\n",
       " 10181,\n",
       " 19939,\n",
       " 10025,\n",
       " 14525,\n",
       " 14249,\n",
       " 17070,\n",
       " 19247,\n",
       " 6749,\n",
       " 190,\n",
       " 18410,\n",
       " 14488,\n",
       " 11533,\n",
       " 4861,\n",
       " 7487,\n",
       " 15113,\n",
       " 8250,\n",
       " 8229,\n",
       " 13464,\n",
       " 13520,\n",
       " 10287,\n",
       " 10263,\n",
       " 12585,\n",
       " 16545,\n",
       " 5833,\n",
       " 3614,\n",
       " 15996,\n",
       " 16449,\n",
       " ...]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_dataset.subset_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567fd48-cfb4-4213-b15d-16286e4cb0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab032909-27ba-4c2b-abaa-e9e26b7c3189",
   "metadata": {},
   "source": [
    "## TEST on 2 Layer Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee5f9186-0a07-4aff-b19f-d67ce965c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(imdb_train_dataset, batch_size=64,\n",
    "                        shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1c6c896-2792-47e4-bca3-00d331ae2967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2172ebca-d63f-47e6-8f52-68864a039959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, output_dim):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, embedded):\n",
    "        x = torch.relu(self.fc1(embedded))\n",
    "        output = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa394af3-ce88-4712-8260-2fb87c7048e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 2  # 二分类问题，输出维度为2\n",
    "embedding_dim = 100\n",
    "model = SimpleClassifier(embedding_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b036c2b0-1051-4264-a166-025408ff5bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0df5c6c5de6450d9faff1d7eb9f249b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ae3ddf91ca475ca196628d3bfd87b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b9e9aa37a44537b6e7cef5931ace9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f25630e415148a9975957f2722c728f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa12525eb4e4eda93f58f2b104d11a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(dataloader):\n",
    "        embedding, labels = batch\n",
    "        labels = labels.to(torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(embedding)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1198ed06-fb40-475f-95f0-8cc1b12628d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_test_dataset = IMDbDataset(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca008e2d-1c89-49f6-9b7f-dd442bf8c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(imdb_test_dataset, batch_size=64,\n",
    "                        shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0df0fbee-af9e-4f8f-baec-00d2cc09c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上评估模型\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        embedding, labels = batch\n",
    "        labels = labels.to(torch.long)\n",
    "        predictions = model(embedding)\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e7ec2e3-4e41-4c2f-b5f4-272b3ebaf441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.79%\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8f0109ff-efaa-4388-83be-288ef7fd0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = IMDbDataLoader(imdb_train_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bd3ec7a6-4c1a-4786-8637-4499bfbef770",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in range(len(imdb_train_dataset)):\n",
    "    text = imdb_train_dataset.__getitem__(i).text\n",
    "    word_vectors = [glove[word.lower()] for word in text if word in glove.stoi]\n",
    "    sentences.append(torch.stack(word_vectors).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b431d11c-2a5f-4801-a080-60cae2df6c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "764911c4-6f28-4610-80ac-e8671b423a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 100])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
