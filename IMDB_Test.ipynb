{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9605f63c-f46a-4993-ae94-41db47247ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8cac37f-dee3-4941-b995-7f3b2739ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, split='train', max_vocab_size=20000, embedding_dim=100):\n",
    "\n",
    "        RANDOM_SEED = 0\n",
    "\n",
    "        self.TEXT = data.Field(tokenize='spacy', include_lengths=True)\n",
    "        self.LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "        train_data, test_data = datasets.IMDB.splits(self.TEXT, self.LABEL)\n",
    "        train_data, valid_data = train_data.split(random_state=random.seed(RANDOM_SEED), \n",
    "                                                  split_ratio=0.8)\n",
    "\n",
    "        self.TEXT.build_vocab(train_data, max_size=max_vocab_size, vectors=f\"glove.6B.{embedding_dim}d\")\n",
    "        self.LABEL.build_vocab(train_data)\n",
    "\n",
    "        if split == 'train':\n",
    "            self.data = train_data\n",
    "        elif split == 'valid':\n",
    "            self.data = valid_data\n",
    "        elif split == 'test':\n",
    "            self.data = test_data\n",
    "        else:\n",
    "            raise ValueError(\"Invalid split. Use 'train', 'valid', or 'test'.\")\n",
    "\n",
    "        self.fields = {'text': self.TEXT, 'label': self.LABEL}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data[idx]\n",
    "        text = example.text\n",
    "        label = example.label\n",
    "        \n",
    "        return data.Example.fromlist([text, label], fields=[('text', self.TEXT), ('label', self.LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9946593e-9a54-43b2-b008-9d338a12bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataLoader:\n",
    "    def __init__(self, dataset, batch_size=64):\n",
    "        self.batch_size = batch_size\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Ensure `sort_key` is set based on the length of the text sequence\n",
    "        sort_key = lambda x: len(x.text)\n",
    "\n",
    "        # Create BucketIterator with the correct sort_key\n",
    "        self.iterator = data.BucketIterator(\n",
    "            dataset=dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sort_key=sort_key,  # Add sort_key here\n",
    "            sort_within_batch=True,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.iterator)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8249cb05-fe2c-41fe-b805-423232d7c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train_dataset = IMDbDataset(split='train')\n",
    "train_loader = IMDbDataLoader(imdb_train_dataset)\n",
    "for x in train_loader:\n",
    "    text, text_len = x.text\n",
    "    print(text.shape)\n",
    "    print(text_len.shape)\n",
    "    print(x.label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc8bd1db-5a43-4781-b50c-6d0636a740ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_deletion(tokens, p=0.5):\n",
    "    if len(tokens) == 0:\n",
    "        return tokens\n",
    "\n",
    "    mask = np.random.rand(len(tokens)) > p\n",
    "    remaining_tokens = list(np.array(tokens)[mask])\n",
    "    # remaining_tokens = [token for token in tokens if random.uniform(0, 1) > p]\n",
    "    if len(remaining_tokens) == 0:\n",
    "        return [random.choice(tokens)]  # 如果全部删除，则随机保留一个\n",
    "    return remaining_tokens\n",
    "\n",
    "class AugmentedIMDbDataset(IMDbDataset):\n",
    "    def __init__(self, split='train', max_vocab_size=20000, embedding_dim=100, augment_function = None, num_positive=2):\n",
    "        super().__init__(split, max_vocab_size, embedding_dim)\n",
    "        self.num_positive = num_positive\n",
    "        self.augment_function = augment_function\n",
    "\n",
    "        augmented_examples = []\n",
    "        for example in self.data.examples:\n",
    "            for _ in range(self.num_positive):\n",
    "                example_augmented_text = self.augment_function(example.text)\n",
    "                new_example = data.Example.fromlist(\n",
    "                    [example_augmented_text, example.label], \n",
    "                    [('text', self.TEXT), ('label', self.LABEL)]\n",
    "                )\n",
    "                augmented_examples.append(new_example)\n",
    "        self.data.examples = augmented_examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return super().__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e06f0930-326b-4662-bd3f-05c8e390b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_imdb_train_dataset = AugmentedIMDbDataset(split='train',\n",
    "                                                    augment_function=random_deletion,\n",
    "                                                    num_positive=2)\n",
    "augmented_imdb_train_loader = IMDbDataLoader(augmented_imdb_train_dataset, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b8fb853-4a3b-4c70-8ed9-4063fe3273d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([516, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the loader to check the augmented samples\n",
    "for batch in augmented_imdb_train_loader:\n",
    "    text, text_length = batch.text\n",
    "    label = batch.label\n",
    "    print(text.shape)\n",
    "    print(text_length.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9eac90-f9e4-4acf-9924-9e2c71fb1a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0474499c-3fde-4943-8eb8-d1a9e4b73e41",
   "metadata": {},
   "source": [
    "## CLIP APPROX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840aa8b8-1789-4c90-9ccc-5fab8287ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9fd8650-08e4-4bd3-9f35-192f4b592e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbGloveEmbeddedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, split='train', max_vocab_size=20000, embedding_dim=100):\n",
    "\n",
    "        RANDOM_SEED = 0\n",
    "\n",
    "        self.TEXT = data.Field(tokenize='spacy', include_lengths=True)\n",
    "        self.LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "        train_data, test_data = datasets.IMDB.splits(self.TEXT, self.LABEL)\n",
    "        train_data, valid_data = train_data.split(random_state=random.seed(RANDOM_SEED), \n",
    "                                                  split_ratio=0.8)\n",
    "\n",
    "        self.TEXT.build_vocab(train_data, max_size=max_vocab_size, vectors=f\"glove.6B.{embedding_dim}d\")\n",
    "        self.LABEL.build_vocab(train_data)\n",
    "\n",
    "        if split == 'train':\n",
    "            self.data = train_data\n",
    "        elif split == 'valid':\n",
    "            self.data = valid_data\n",
    "        elif split == 'test':\n",
    "            self.data = test_data\n",
    "        else:\n",
    "            raise ValueError(\"Invalid split. Use 'train', 'valid', or 'test'.\")\n",
    "\n",
    "        glove = GloVe(name='6B', dim=embedding_dim)\n",
    "        \n",
    "        texts = []\n",
    "        labels = []\n",
    "        \n",
    "        for sample in self.data:\n",
    "            text = sample.text\n",
    "            label = (1 if sample.label == 'pos' else 0)\n",
    "            \n",
    "            word_vectors = [glove[word.lower()] for word in text if word.lower() in glove.stoi]\n",
    "            texts.append(torch.stack(word_vectors).mean(0))\n",
    "            labels.append(label)\n",
    "        self.X = torch.stack(texts)\n",
    "        self.y = torch.Tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aa4641bb-19c5-42f0-9426-ba713d0ae3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91d37784-996c-4b89-9801-e704d59ed109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_using_glove(dataset, device):\n",
    "    glove = GloVe(name='6B', dim=100)\n",
    "    texts = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        sample = dataset[i]\n",
    "        word_vectors = [glove[word.lower()] for word in sample.text if word.lower() in glove.stoi]\n",
    "        texts.append(torch.stack(word_vectors).mean(0))\n",
    "        \n",
    "    Z = torch.stack(texts).to(device)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6668b62-2363-4a97-b6a8-f849de50a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_classifier(\n",
    "    X: torch.tensor, \n",
    "    y: torch.tensor, \n",
    "    representation_dim: int,\n",
    "    num_classes: int,\n",
    "    device: torch.device,\n",
    "    reg_weight: float = 1e-3,\n",
    "    n_lbfgs_steps: int = 500,\n",
    "    verbose=False,\n",
    "):\n",
    "    if verbose:\n",
    "        print('\\nL2 Regularization weight: %g' % reg_weight)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    X_gpu = X.to(device)\n",
    "    y_gpu = y.to(device)\n",
    "\n",
    "    # Should be reset after each epoch for a completely independent evaluation\n",
    "    clf = nn.Linear(representation_dim, num_classes).to(device)\n",
    "    clf_optimizer = optim.LBFGS(clf.parameters())\n",
    "    clf.train()\n",
    "\n",
    "    for _ in tqdm(range(n_lbfgs_steps), desc=\"Training linear classifier using fraction of labels\", disable=not verbose):\n",
    "        def closure():\n",
    "            clf_optimizer.zero_grad()\n",
    "            raw_scores = clf(X_gpu)\n",
    "            loss = criterion(raw_scores, y_gpu)\n",
    "            loss += reg_weight * clf.weight.pow(2).sum()\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        clf_optimizer.step(closure)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92f976f0-e303-4db4-b407-99963f603083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_from_preds(preds):\n",
    "    partition = {}\n",
    "    for i, pred in enumerate(preds):\n",
    "        if pred not in partition:\n",
    "            partition[pred] = []\n",
    "        partition[pred].append(i)\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea04d93e-6021-47f0-bcf4-1b8be8dee181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_approx(\n",
    "    trainset: torch.utils.data.Dataset,\n",
    "    labeled_example_indices: List[int], \n",
    "    labeled_examples_labels: np.array,\n",
    "    num_classes: int,\n",
    "    device: torch.device, \n",
    "    batch_size: int = 512,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    Z = encode_using_glove(trainset, device)\n",
    "    clf = train_linear_classifier(\n",
    "        X=Z[labeled_example_indices], \n",
    "        y=torch.tensor(labeled_examples_labels), \n",
    "        representation_dim=len(Z[0]),\n",
    "        num_classes=num_classes,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )\n",
    "    preds = []\n",
    "    for start_idx in range(0, len(Z), batch_size):\n",
    "        preds.append(torch.argmax(clf(Z[start_idx:start_idx + batch_size]).detach(), dim=1).cpu())\n",
    "    preds = torch.cat(preds).numpy()\n",
    "\n",
    "    return partition_from_preds(preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08490ff8-7e2f-4834-be92-976385b4a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_labeled_examples_indices = random.sample(range(len(imdb_train_dataset)), 500)\n",
    "rand_labeled_examples_labels = [\n",
    "    1 if imdb_train_dataset[i].label == 'pos' else 0 for i in rand_labeled_examples_indices\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcf73219-58d7-4ef0-91a7-fab578b6666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train_dataset = IMDbDataset(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52812ed7-b79f-4b06-8dc0-d7715626debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = glove_approx(\n",
    "    trainset=imdb_train_dataset,\n",
    "    labeled_example_indices=rand_labeled_examples_indices, \n",
    "    labeled_examples_labels=rand_labeled_examples_labels,\n",
    "    num_classes=2,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498f7a0-32d9-4ab1-819e-41a40703a71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8d025d7-286b-4c7f-baf3-577b8a4ec619",
   "metadata": {},
   "source": [
    "## SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33fcf817-f3a8-4972-b543-eb0a14e7eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "from typing import Dict, List, Optional\n",
    "import math \n",
    "import pickle\n",
    "import random \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sas.submodular_maximization import lazy_greedy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f209e2e2-5313-4a1b-a1e8-8341cfb35acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "\n",
    "class ProxyModel(nn.Module):\n",
    "    def __init__(self, net, critic):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.critic = critic\n",
    "    def forward(self, x):\n",
    "        return self.critic.project(self.net(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a89b8f71-b200-4aef-a488-0389093b49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSubsetDataset(ABC, Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: Dataset,\n",
    "        subset_fraction: float,\n",
    "        verbose: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param dataset: Original Dataset\n",
    "        :type dataset: Dataset\n",
    "        :param subset_fraction: Fractional size of subset\n",
    "        :type subset_fraction: float\n",
    "        :param verbose: verbose\n",
    "        :type verbose: boolean\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.subset_fraction = subset_fraction\n",
    "        self.len_dataset = len(self.dataset)\n",
    "        self.subset_size = int(self.len_dataset * self.subset_fraction)\n",
    "        self.subset_indices = None\n",
    "        self.verbose = verbose \n",
    "\n",
    "    def initialization_complete(self):\n",
    "        if self.verbose:\n",
    "            print(f\"Subset Size: {self.subset_size}\")\n",
    "            print(f\"Discarded {self.len_dataset - self.subset_size} examples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.subset_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get the index for the corresponding item in the original dataset\n",
    "        original_index = self.subset_indices[index]\n",
    "        \n",
    "        # Get the item from the original dataset at the corresponding index\n",
    "        original_item = self.dataset[original_index]\n",
    "        \n",
    "        return original_item\n",
    "    \n",
    "    def save_to_file(self, filename):\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(self.subset_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4acec1e0-7b4c-4e3c-81ea-9771e2070236",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SASSubsetDataset(BaseSubsetDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: Dataset,\n",
    "        subset_fraction: float,\n",
    "        num_downstream_classes: int,\n",
    "        device: torch.device,\n",
    "        approx_latent_class_partition: Dict[int, int],\n",
    "        proxy_model: Optional[nn.Module] = None,\n",
    "        augmentation_distance: Optional[Dict[int, np.array]] = None,\n",
    "        num_runs=1,\n",
    "        pairwise_distance_block_size: int = 1024, \n",
    "        threshold: float = 0.0,\n",
    "        verbose: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        dataset: Dataset\n",
    "            Original dataset for contrastive learning. Assumes that dataset[i] returns a list of augmented views of the original example i.\n",
    "\n",
    "        subset_fraction: float\n",
    "            Fractional size of subset.\n",
    "\n",
    "        num_downstream_classes: int\n",
    "            Number of downstream classes (can be an estimate).\n",
    "\n",
    "        proxy_model: nn.Module\n",
    "            Proxy model to calculate the augmentation distance (and kmeans clustering if the avoid clip option is chosen).\n",
    "\n",
    "        augmentation_distance: Dict[int, np.array]\n",
    "            Pass a precomputed dictionary containing augmentation distance for each latent class.\n",
    "\n",
    "        num_augmentations: int\n",
    "            Number of augmentations to consider while approximating the augmentation distance.\n",
    "\n",
    "        pairwise_distance_block_size: int\n",
    "            Block size for calculating pairwise distance. This is just to optimize GPU usage while calculating pairwise distance and will not affect the subset created in any way.\n",
    "\n",
    "        verbose: boolean\n",
    "            Verbosity of the output.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            dataset=dataset, \n",
    "            subset_fraction=subset_fraction,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        self.device = device\n",
    "        self.num_downstream_classes = num_downstream_classes\n",
    "        self.proxy_model = proxy_model\n",
    "        self.partition = approx_latent_class_partition\n",
    "        self.augmentation_distance = augmentation_distance\n",
    "        self.num_runs = num_runs\n",
    "        self.pairwise_distance_block_size = pairwise_distance_block_size\n",
    "\n",
    "        if self.augmentation_distance == None:\n",
    "            self.augmentation_distance = self.approximate_augmentation_distance()\n",
    "\n",
    "        class_wise_idx = {}\n",
    "        for latent_class in tqdm(self.partition.keys(), desc=\"Subset Selection:\", disable=not verbose):\n",
    "            F = SubsetSelectionObjective(self.augmentation_distance[latent_class].copy(), threshold=threshold)\n",
    "            class_wise_idx[latent_class] = lazy_greedy(F, range(len(self.augmentation_distance[latent_class])), len(self.augmentation_distance[latent_class]))\n",
    "            class_wise_idx[latent_class] = [self.partition[latent_class][i] for i in class_wise_idx[latent_class]]\n",
    "            \n",
    "        self.subset_indices = []\n",
    "        for latent_class in class_wise_idx.keys():\n",
    "            l = len(class_wise_idx[latent_class])\n",
    "            self.subset_indices.extend(class_wise_idx[latent_class][:int(self.subset_fraction * l)])\n",
    "\n",
    "        self.initialization_complete()\n",
    "\n",
    "\n",
    "    def approximate_augmentation_distance(self):\n",
    "        self.proxy_model = self.proxy_model.to(self.device)\n",
    "\n",
    "        # Initialize augmentation distance with all 0s\n",
    "        augmentation_distance = {}\n",
    "        Z = self.encode_trainset()\n",
    "        for latent_class in self.partition.keys():\n",
    "            Z_partition = Z[self.partition[latent_class]]\n",
    "            pairwise_distance = SASSubsetDataset.pairwise_distance(Z_partition, Z_partition)\n",
    "            augmentation_distance[latent_class] = pairwise_distance.copy()\n",
    "        return augmentation_distance\n",
    "\n",
    "    def encode_trainset(self):\n",
    "        trainloader = torch.utils.data.DataLoader(self.dataset, batch_size=self.pairwise_distance_block_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "        with torch.no_grad():\n",
    "            Z = []\n",
    "            for input in trainloader:\n",
    "                Z.append(self.proxy_model(input[0].to(self.device)))\n",
    "        return torch.cat(Z, dim=0)\n",
    "    \n",
    "    def encode_augmented_trainset(self, num_positives=1):\n",
    "        trainloader = torch.utils.data.DataLoader(self.dataset, batch_size=self.pairwise_distance_block_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "        with torch.no_grad():\n",
    "            Z = []\n",
    "            for _ in range(num_positives):\n",
    "                Z.append([])\n",
    "            for X in trainloader:\n",
    "                for j in range(num_positives):\n",
    "                    Z[j].append(self.proxy_model(X[j].to(self.device)))\n",
    "        for i in range(num_positives):\n",
    "            Z[i] = torch.cat(Z[i], dim=0)\n",
    "        Z = torch.cat(Z, dim=0)\n",
    "        return Z\n",
    "\n",
    "    @staticmethod\n",
    "    def pairwise_distance(Z1: torch.tensor, Z2: torch.tensor, block_size: int = 1024):\n",
    "        similarity_matrices = []\n",
    "        for i in range(Z1.shape[0] // block_size + 1):\n",
    "            similarity_matrices_i = []\n",
    "            e = Z1[i*block_size:(i+1)*block_size]\n",
    "            for j in range(Z2.shape[0] // block_size + 1):\n",
    "                e_t = Z2[j*block_size:(j+1)*block_size].t()\n",
    "                similarity_matrices_i.append(\n",
    "                    np.array(\n",
    "                    torch.cosine_similarity(e[:, :, None], e_t[None, :, :]).detach().cpu()\n",
    "                    )\n",
    "                )\n",
    "            similarity_matrices.append(similarity_matrices_i)\n",
    "        similarity_matrix = np.block(similarity_matrices)\n",
    "\n",
    "        return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d72db7-78b5-4f71-bab6-c3cb6c85db83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3cf7f-b2e1-4ac2-becd-3025129aa9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "395ed8c0-cd93-42a2-b9cb-b4ce4c0cdb39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/xiyang/miniconda3/envs/sas/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/xiyang/miniconda3/envs/sas/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/xiyang/miniconda3/envs/sas/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/xiyang/miniconda3/envs/sas/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 150, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torchtext.data.example.Example'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m critic \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-12-0317:57:33.875617-imdb-LSTM-99-critic.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m proxy_model \u001b[38;5;241m=\u001b[39m ProxyModel(net, critic)\n\u001b[0;32m----> 7\u001b[0m subset_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSASSubsetDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimdb_train_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_downstream_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxy_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxy_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapprox_latent_class_partition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/site-packages/sas/subset_dataset.py:204\u001b[0m, in \u001b[0;36mSASSubsetDataset.__init__\u001b[0;34m(self, dataset, subset_fraction, num_downstream_classes, device, approx_latent_class_partition, proxy_model, augmentation_distance, num_runs, pairwise_distance_block_size, threshold, verbose)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpairwise_distance_block_size \u001b[38;5;241m=\u001b[39m pairwise_distance_block_size\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmentation_distance \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmentation_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapproximate_augmentation_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m class_wise_idx \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m latent_class \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartition\u001b[38;5;241m.\u001b[39mkeys(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubset Selection:\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m verbose):\n",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/site-packages/sas/subset_dataset.py:225\u001b[0m, in \u001b[0;36mSASSubsetDataset.approximate_augmentation_distance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# Initialize augmentation distance with all 0s\u001b[39;00m\n\u001b[1;32m    224\u001b[0m augmentation_distance \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 225\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_trainset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m latent_class \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartition\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    227\u001b[0m     Z_partition \u001b[38;5;241m=\u001b[39m Z[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartition[latent_class]]\n",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/site-packages/sas/subset_dataset.py:236\u001b[0m, in \u001b[0;36mSASSubsetDataset.encode_trainset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    235\u001b[0m     Z \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m trainloader:\n\u001b[1;32m    237\u001b[0m         Z\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy_model(\u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)))\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(Z, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/sas/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/xiyang/miniconda3/envs/sas/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/xiyang/miniconda3/envs/sas/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/xiyang/miniconda3/envs/sas/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/xiyang/miniconda3/envs/sas/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 150, in collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torchtext.data.example.Example'>\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from sas.subset_dataset import SASSubsetDataset\n",
    "net = torch.load(\"2023-12-0317:57:33.875617-imdb-LSTM-99-net.pt\")\n",
    "critic = torch.load(\"2023-12-0317:57:33.875617-imdb-LSTM-99-critic.pt\")\n",
    "proxy_model = ProxyModel(net, critic)\n",
    "     \n",
    "subset_dataset = SASSubsetDataset(\n",
    "    dataset=imdb_train_dataset,\n",
    "    subset_fraction=0.2,\n",
    "    num_downstream_classes=2,\n",
    "    device=device,\n",
    "    proxy_model=proxy_model,\n",
    "    approx_latent_class_partition=partition,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c01698-ab67-4c77-a6b9-e13de3adbef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567fd48-cfb4-4213-b15d-16286e4cb0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab032909-27ba-4c2b-abaa-e9e26b7c3189",
   "metadata": {},
   "source": [
    "## TEST on 2 Layer Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee5f9186-0a07-4aff-b19f-d67ce965c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(imdb_train_dataset, batch_size=64,\n",
    "                        shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1c6c896-2792-47e4-bca3-00d331ae2967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2172ebca-d63f-47e6-8f52-68864a039959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, output_dim):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, embedded):\n",
    "        x = torch.relu(self.fc1(embedded))\n",
    "        output = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa394af3-ce88-4712-8260-2fb87c7048e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 2  # 二分类问题，输出维度为2\n",
    "embedding_dim = 100\n",
    "model = SimpleClassifier(embedding_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b036c2b0-1051-4264-a166-025408ff5bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0df5c6c5de6450d9faff1d7eb9f249b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ae3ddf91ca475ca196628d3bfd87b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b9e9aa37a44537b6e7cef5931ace9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f25630e415148a9975957f2722c728f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa12525eb4e4eda93f58f2b104d11a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(dataloader):\n",
    "        embedding, labels = batch\n",
    "        labels = labels.to(torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(embedding)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1198ed06-fb40-475f-95f0-8cc1b12628d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_test_dataset = IMDbDataset(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca008e2d-1c89-49f6-9b7f-dd442bf8c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(imdb_test_dataset, batch_size=64,\n",
    "                        shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0df0fbee-af9e-4f8f-baec-00d2cc09c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上评估模型\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        embedding, labels = batch\n",
    "        labels = labels.to(torch.long)\n",
    "        predictions = model(embedding)\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e7ec2e3-4e41-4c2f-b5f4-272b3ebaf441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 77.79%\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8f0109ff-efaa-4388-83be-288ef7fd0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = IMDbDataLoader(imdb_train_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bd3ec7a6-4c1a-4786-8637-4499bfbef770",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in range(len(imdb_train_dataset)):\n",
    "    text = imdb_train_dataset.__getitem__(i).text\n",
    "    word_vectors = [glove[word.lower()] for word in text if word in glove.stoi]\n",
    "    sentences.append(torch.stack(word_vectors).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b431d11c-2a5f-4801-a080-60cae2df6c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "764911c4-6f28-4610-80ac-e8671b423a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 100])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
